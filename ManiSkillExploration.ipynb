{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Setup Vulkan for ManiSkill on Colab\n",
        "!sudo mkdir -p /usr/share/vulkan/icd.d\n",
        "!sudo mkdir -p /usr/share/glvnd/egl_vendor.d\n",
        "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill/main/docker/nvidia_icd.json\n",
        "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill/main/docker/10_nvidia.json\n",
        "!sudo mv nvidia_icd.json /usr/share/vulkan/icd.d/\n",
        "!sudo mv 10_nvidia.json /usr/share/glvnd/egl_vendor.d/10_nvidia.json\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y --no-install-recommends libvulkan-dev\n",
        "\n",
        "# Install ManiSkill dependencies\n",
        "!pip install -U \"mani_skill[dev]\" tyro"
      ],
      "metadata": {
        "id": "j-ztist1aCPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import gymnasium as gym\n",
        "import mani_skill.envs\n",
        "import time\n",
        "env = gym.make(\"PegInsertionSide-v1\")\n",
        "obs, _ = env.reset(seed=0)\n",
        "env.unwrapped.print_sim_details() # print verbose details about the configuration\n",
        "done = False\n",
        "start_time = time.time()\n",
        "while not done:\n",
        "    obs, rew, terminated, truncated, info = env.step(env.action_space.sample())\n",
        "    done = terminated or truncated\n",
        "N = info[\"elapsed_steps\"].item()\n",
        "dt = time.time() - start_time\n",
        "FPS = N / (dt)\n",
        "print(f\"Frames Per Second = {N} / {dt} = {FPS}\")"
      ],
      "metadata": {
        "id": "3U8ZeHZqaDG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mani_skill.utils.wrappers import CPUGymWrapper\n",
        "env = gym.make(\"PegInsertionSide-v1\")\n",
        "env = CPUGymWrapper(env)\n",
        "obs, _ = env.reset() # obs is numpy and unbatched\n",
        "print(type(obs), obs.shape)"
      ],
      "metadata": {
        "id": "0ZcwPinuaIfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch # Import torch for using cpu()\n",
        "\n",
        "env = gym.make(\"PegInsertionSide-v1\", render_mode=\"rgb_array\")\n",
        "env.reset()\n",
        "# Move the tensor to CPU before converting to NumPy array\n",
        "plt.imshow(env.render()[0].cpu().numpy()) # we take [0].numpy() as everything is a batched tensor"
      ],
      "metadata": {
        "id": "2zlpLjngaLcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Make sure to restart the notebook if you already ran a CPU sim!! ###\n",
        "# Import required packages\n",
        "import gymnasium as gym\n",
        "import mani_skill.envs\n",
        "import torch\n",
        "import time\n",
        "num_envs = 2048 # you can go up to 4096 on better GPUs\n",
        "env = gym.make(\"PickCube-v1\", num_envs=num_envs)\n",
        "env.unwrapped.print_sim_details()\n",
        "obs, _ = env.reset(seed=0)\n",
        "done = False\n",
        "start_time = time.time()\n",
        "total_rew = 0\n",
        "while not done:\n",
        "    # note that env.action_space is now a batched action space\n",
        "    obs, rew, terminated, truncated, info = env.step(torch.from_numpy(env.action_space.sample()))\n",
        "    done = (terminated | truncated).any() # stop if any environment terminates/truncates\n",
        "N = num_envs * info[\"elapsed_steps\"][0].item()\n",
        "dt = time.time() - start_time\n",
        "FPS = N / (dt)\n",
        "print(f\"Frames Per Second = {N} / {dt} = {FPS}\")"
      ],
      "metadata": {
        "id": "jJdItroVecbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import gymnasium as gym\n",
        "import mani_skill.envs\n",
        "import torch\n",
        "import time\n",
        "num_envs = 512 # you can go up higher on better GPUs, this is mostly memory constrained\n",
        "env = gym.make(\"PickCube-v1\", num_envs=num_envs, obs_mode=\"rgbd\")\n",
        "env.unwrapped.print_sim_details()\n",
        "obs, _ = env.reset(seed=0)\n",
        "done = False\n",
        "start_time = time.time()\n",
        "total_rew = 0\n",
        "while not done:\n",
        "    # note that env.action_space is now a batched action space\n",
        "    obs, rew, terminated, truncated, info = env.step(torch.from_numpy(env.action_space.sample()))\n",
        "    done = (terminated | truncated).any() # stop if any environment terminates/truncates\n",
        "N = num_envs * info[\"elapsed_steps\"][0].item()\n",
        "dt = time.time() - start_time\n",
        "FPS = N / (dt)\n",
        "print(f\"Frames Per Second = {N} / {dt} = {FPS}\")"
      ],
      "metadata": {
        "id": "cN2NBbyzDB6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the image data from the environment and inspect the data\n",
        "print(obs.keys())\n",
        "print(obs['sensor_data'].keys())\n",
        "print(obs['sensor_data']['base_camera'].keys())\n",
        "print(obs['sensor_data']['base_camera']['rgb'].shape)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs['sensor_data']['base_camera']['rgb'][0].cpu().numpy())"
      ],
      "metadata": {
        "id": "UQZA5NYNDdod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import gymnasium as gym\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import mani_skill.envs\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nyB_kRPhDnBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Run this cell to display the action space of the chosen controller as well as the current view of the environment\n",
        "# Can be any env_id from the list of Rigid-Body envs: https://maniskill.readthedocs.io/en/latest/tasks/index.html\n",
        "env_id = \"PickCube-v1\" #@param ['PickCube-v1', 'PegInsertionSide-v1', 'StackCube-v1']\n",
        "\n",
        "# choose an observation type and space, see https://maniskill.readthedocs.io/en/latest/user_guide/concepts/observation.html for details\n",
        "obs_mode = \"pointcloud\" #@param can be one of ['pointcloud', 'rgb+depth+segmentation', 'state_dict', 'state']\n",
        "\n",
        "# choose a controller type / action space, see https://maniskill.readthedocs.io/en/latest/user_guide/concepts/controllers.html for a full list\n",
        "control_mode = \"pd_joint_delta_pos\" #@param can be one of ['pd_ee_delta_pose', 'pd_ee_delta_pos', 'pd_joint_delta_pos', 'arm_pd_joint_pos_vel']\n",
        "\n",
        "reward_mode = \"dense\" #@param can be one of ['sparse', 'dense']\n",
        "\n",
        "robot_uids = \"panda\" #@param can be one of ['panda', 'fetch']\n",
        "\n",
        "# create an environment with our configs and then reset to a clean state\n",
        "env = gym.make(env_id,\n",
        "               num_envs=4,\n",
        "               obs_mode=obs_mode,\n",
        "               reward_mode=reward_mode,\n",
        "               control_mode=control_mode,\n",
        "               robot_uids=robot_uids,\n",
        "               enable_shadow=True # this makes the default lighting cast shadows\n",
        "               )\n",
        "obs, _ = env.reset()\n",
        "print(\"Action Space:\", env.action_space)\n",
        "\n",
        "# take a look at the current state of the 4 parallel environments we created\n",
        "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
        "rgbs = env.render_rgb_array() # this is a easy way to get the rgb array without having to set render_mode\n",
        "for i, ax in enumerate(axs.flatten()):\n",
        "    ax.imshow(rgbs[i].cpu().numpy())\n",
        "    ax.axis(\"off\")\n",
        "plt.suptitle(\"Current States viewed from external cameras\")\n",
        "fig.tight_layout()\n",
        "env.close()"
      ],
      "metadata": {
        "id": "ZfwRJFc3Yl02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some visualization functions for different observation modes\n",
        "def show_camera_view(obs_camera, title, env_id=0):\n",
        "    plt.figure()\n",
        "    rgb, depth = obs_camera['rgb'], obs_camera['depth']\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(f\"{title} - RGB\")\n",
        "    plt.imshow(rgb[env_id].cpu().numpy())\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(f\"{title} - Depth\")\n",
        "    plt.imshow(depth[..., 0][env_id].cpu().numpy(), cmap=\"gray\")\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.title(f\"{title} - Segmentation\")\n",
        "    plt.imshow(obs_camera[\"segmentation\"][..., 0][env_id].cpu().numpy())\n",
        "\n",
        "def show_pointcloud(obs, env_id=0):\n",
        "    import trimesh\n",
        "    v = obs['pointcloud']['xyzw'][env_id, ..., :3].cpu().numpy()\n",
        "    cam2world = obs[\"sensor_param\"][\"base_camera\"][\"cam2world_gl\"][env_id].cpu().numpy()\n",
        "    cam2world = cam2world\n",
        "    camera = trimesh.scene.Camera(\"camera\", (1024, 1024), fov=(np.rad2deg(np.pi/2), np.rad2deg(np.pi/2)))\n",
        "    s = trimesh.Scene([trimesh.points.PointCloud(v, obs['pointcloud']['rgb'][env_id].cpu().numpy())], camera=camera, camera_transform=cam2world)\n",
        "    return s.show()"
      ],
      "metadata": {
        "id": "PTk2V9WncMgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Display the RGBD+Segmentation observation. Make sure you are using `obs_mode=\"rgbd\"`\n",
        "show_camera_view(obs['sensor_data']['base_camera'], \"Base\")"
      ],
      "metadata": {
        "id": "ahDRjAnhcPIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Display one of the Pointcloud observations. Make sure you are using `obs_mode=\"pointcloud\"`\n",
        "show_pointcloud(obs)"
      ],
      "metadata": {
        "id": "ln0G7CJDcW4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import mani_skill.envs\n",
        "from tqdm.notebook import tqdm\n",
        "from mani_skill.utils.wrappers import RecordEpisode\n",
        "# to make it look a little more realistic, we will enable shadows which make the default lighting cast shadows\n",
        "env = gym.make(\"PickCube-v1\", num_envs=4, render_mode=\"rgb_array\", enable_shadow=True)\n",
        "env = RecordEpisode(\n",
        "    env,\n",
        "    \"./videos\", # the directory to save replay videos and trajectories to\n",
        "    # on GPU sim we record intervals, not by single episodes as there are multiple envs\n",
        "    # each 100 steps a new video is saved\n",
        "    max_steps_per_video=100\n",
        ")\n",
        "\n",
        "# step through the environment with random actions\n",
        "obs, _ = env.reset()\n",
        "for i in tqdm(range(100)):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, terminated, truncated, info = env.step(torch.from_numpy(action))\n",
        "    # env.render_human() # will render with a window if possible\n",
        "env.close()\n",
        "from IPython.display import Video\n",
        "Video(\"./videos/0.mp4\", embed=True, width=640) # Watch our replay"
      ],
      "metadata": {
        "id": "_eH3U2wLdEsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m mani_skill.examples.teleoperation.interactive_panda -e \"StackCube-v1\""
      ],
      "metadata": {
        "id": "ZfXaCDwtgwbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<video controls width=800>\n",
        "<source src=\"https://github.com/haosulab/ManiSkill/raw/main/docs/source/_static/videos/teleop-stackcube-demo.mp4\">\n",
        "</video>"
      ],
      "metadata": {
        "id": "8hbNyx6LhZhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 Reinforcement Learning"
      ],
      "metadata": {
        "id": "wxB8wKlKhqSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video"
      ],
      "metadata": {
        "id": "MISFDA8khqA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/haosulab/ManiSkill/main/examples/baselines/ppo/ppo.py -O ppo.py\n",
        "!wget https://raw.githubusercontent.com/haosulab/ManiSkill/main/examples/baselines/ppo/ppo_rgb.py -O ppo_rgb.py"
      ],
      "metadata": {
        "id": "RIHgis7oh5M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "6BRH2eo2h_QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ppo.py --env_id=\"PushCube-v1\" --exp-name=\"state-pushcube\" \\\n",
        "  --num_envs=1024 --update_epochs=8 --num_minibatches=32 \\\n",
        "  --total_timesteps=600_000 --eval_freq=8 --num-steps=20"
      ],
      "metadata": {
        "id": "rAVhwEIuiBd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Video(\"runs/state-pushcube/videos/3.mp4\", embed=True, width=1024) # Watch a replay during training evaluation"
      ],
      "metadata": {
        "id": "JGuq7mHPiuuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ppo_rgb.py --env_id=\"PushCube-v1\" --exp-name=\"rgb-pushcube\" \\\n",
        "  --num_envs=256 --update_epochs=8 --num_minibatches=16 \\\n",
        "  --total_timesteps=250_000 --eval_freq=10 --num-steps=20"
      ],
      "metadata": {
        "id": "GDx2qDo7kV_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ppo_rgb.py --env_id=\"PushCube-v1\" \\\n",
        "  --evaluate --checkpoint=runs/rgb-pushcube/ckpt_41.pt \\\n",
        "  --num_eval_envs=1 --num-eval-steps=100"
      ],
      "metadata": {
        "id": "MpNe6DiskW4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m mani_skill.trajectory.replay_trajectory \\\n",
        "  --traj-path=/content/runs/rgb-pushcube/test_videos/trajectory.h5 --use-env-states \\\n",
        "  --render-mode=\"sensors\" --save-video --allow-failure"
      ],
      "metadata": {
        "id": "tkS4vaVIlfKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Video(\"runs/rgb-pushcube/test_videos/0.mp4\", embed=True, width=256) # Watch our replay from the camera perspective we trained on"
      ],
      "metadata": {
        "id": "aAszSowmlhFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Demonstration Data"
      ],
      "metadata": {
        "id": "_7a82Y8_llwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video"
      ],
      "metadata": {
        "id": "LAdl5WTSln1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m mani_skill.utils.download_demo \"PegInsertionSide-v1\" -o demos"
      ],
      "metadata": {
        "id": "a2BK4T8slwv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Video(\"demos/PegInsertionSide-v1/motionplanning/sample.mp4\", embed=True, width=512)"
      ],
      "metadata": {
        "id": "BRUEB37Tl1Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mani_skill.trajectory.dataset import ManiSkillTrajectoryDataset\n",
        "dataset = ManiSkillTrajectoryDataset(dataset_file=\"demos/PegInsertionSide-v1/motionplanning/trajectory.h5\")\n",
        "data = dataset[150]\n",
        "for k, v in data.items():\n",
        "    print(k, v)"
      ],
      "metadata": {
        "id": "3nhKzziQmIXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "from mani_skill.utils.io_utils import load_json\n",
        "\n",
        "# Load the trajectory data from the .h5 file. Demonstrations are versioned and thus saved to \"demos/<version>/...\"\n",
        "traj_path = f\"demos/PegInsertionSide-v1/motionplanning/trajectory.h5\"\n",
        "# You can also replace the above path with the trajectory you just recorded (./tmp/trajectory.h5)\n",
        "h5_file = h5py.File(traj_path, \"r\")\n",
        "\n",
        "# Load associated json\n",
        "json_path = traj_path.replace(\".h5\", \".json\")\n",
        "json_data = load_json(json_path)\n",
        "\n",
        "episodes = json_data[\"episodes\"] # meta data of each episode\n",
        "env_info = json_data[\"env_info\"]\n",
        "env_id = env_info[\"env_id\"]\n",
        "env_kwargs = env_info[\"env_kwargs\"]\n",
        "\n",
        "print(\"env_id:\", env_id)\n",
        "print(\"env_kwargs:\", env_kwargs)\n",
        "print(\"#episodes:\", len(episodes))\n",
        "print(\"Dataset source:\", json_data[\"source_type\"])\n",
        "print(\"Dataset source description:\", json_data[\"source_desc\"])"
      ],
      "metadata": {
        "id": "ZQ9jW5E9m-Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traj_id = \"traj_0\"\n",
        "traj_h5 = h5_file[traj_id]\n",
        "def print_h5py_structure(traj_h5, prefix=\"\"):\n",
        "    for key in traj_h5:\n",
        "        if isinstance(traj_h5[key], h5py.Group):\n",
        "            print_h5py_structure(traj_h5[key], prefix=prefix + \"/\" + key)\n",
        "        else:\n",
        "            print(prefix + \"/\" + key, traj_h5[key].shape, traj_h5[key].dtype)\n",
        "\n",
        "print_h5py_structure(traj_h5)"
      ],
      "metadata": {
        "id": "dLFK9rOYm-De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mani_skill.trajectory.utils import index_dict, dict_to_list_of_dicts\n",
        "index_dict(traj_h5[\"env_states\"], 23) # select the 23rd element of all values"
      ],
      "metadata": {
        "id": "crPPTIjEnFNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_states = dict_to_list_of_dicts(traj_h5[\"env_states\"]) # convert to a list of dictionaries\n",
        "env_states[23]"
      ],
      "metadata": {
        "id": "yJ1oqNvgnMUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mani_skill.utils.visualization.misc import images_to_video\n",
        "import gymnasium as gym\n",
        "import mani_skill.envs\n",
        "from tqdm.notebook import tqdm\n",
        "def replay(episode_idx, h5_file, json_data, render_mode=\"cameras\", fps=20):\n",
        "    episodes = json_data[\"episodes\"]\n",
        "    ep = episodes[episode_idx]\n",
        "    # episode_id should be the same as episode_idx, unless specified otherwise\n",
        "    episode_id = ep[\"episode_id\"]\n",
        "    traj = h5_file[f\"traj_{episode_id}\"]\n",
        "    env_states = dict_to_list_of_dicts(traj[\"env_states\"])\n",
        "\n",
        "    # Create the environment\n",
        "    env_kwargs = json_data[\"env_info\"][\"env_kwargs\"]\n",
        "    env = gym.make(json_data[\"env_info\"][\"env_id\"], **env_kwargs)\n",
        "    print(env_kwargs)\n",
        "    # Reset the environment\n",
        "    reset_kwargs = ep[\"reset_kwargs\"].copy()\n",
        "    reset_kwargs[\"seed\"] = ep[\"episode_seed\"]\n",
        "    env.reset(**reset_kwargs)\n",
        "\n",
        "    frames = [env.render_rgb_array()[0].numpy()]\n",
        "    for i in tqdm(range(len(traj[\"actions\"]))):\n",
        "        action = traj[\"actions\"][i]\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        env.set_state_dict(env_states[i])\n",
        "        frames.append(env.render_rgb_array()[0].numpy())\n",
        "\n",
        "    env.close()\n",
        "    del env\n",
        "    images_to_video(frames, output_dir=\".\", video_name=\"replay\", fps=30, )"
      ],
      "metadata": {
        "id": "cckvfCRPnY48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Choose an episode ID here and run this cell to watch a replay of a expert demo. Note that this can be a little slow as this code generates a video. To run faster we recommend watching on a machine with a GUI and running only the replay function.\n",
        "\n",
        "episode_idx = 4 #@param {type:\"integer\"}\n",
        "replay(episode_idx, h5_file, json_data)\n",
        "Video(\"./replay.mp4\", embed=True)"
      ],
      "metadata": {
        "id": "DEoxRQxwnb35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m mani_skill.trajectory.replay_trajectory \\\n",
        "    --traj-path demos/PegInsertionSide-v1/motionplanning/trajectory.h5 --save-traj \\\n",
        "    --obs-mode rgbd -c \"pd_joint_delta_pos\" --num-procs 1 --count 2 # only generate 2"
      ],
      "metadata": {
        "id": "8H3GDVWZpLn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mani_skill.trajectory.dataset import ManiSkillTrajectoryDataset\n",
        "import matplotlib.pyplot as plt\n",
        "dataset = ManiSkillTrajectoryDataset(dataset_file=\"demos/PegInsertionSide-v1/motionplanning/trajectory.rgbd.pd_joint_delta_pos.cpu.h5\")\n",
        "data = dataset[0]\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].imshow(data[\"obs\"][\"sensor_data\"][\"hand_camera\"][\"rgb\"])\n",
        "axs[1].imshow(data[\"obs\"][\"sensor_data\"][\"hand_camera\"][\"depth\"])"
      ],
      "metadata": {
        "id": "-NjSnYvApXfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 Heterogeneous Parallel Simulation"
      ],
      "metadata": {
        "id": "sa_5MSYSp1kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import mani_skill.envs\n",
        "from tqdm.notebook import tqdm\n",
        "from mani_skill.utils.wrappers import RecordEpisode\n",
        "from IPython.display import Video"
      ],
      "metadata": {
        "id": "Z_rWsdRPp2Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# asset downloads may vary in speed depending on server\n",
        "!python -m mani_skill.utils.download_asset -y PickClutterYCB-v1\n",
        "!python -m mani_skill.utils.download_asset -y partnet_mobility"
      ],
      "metadata": {
        "id": "A7TAdegHp4hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See section 1.5 for more details on how we create environments and save videos\n",
        "env = gym.make(\"PickClutterYCB-v1\", num_envs=4, render_mode=\"rgb_array\", enable_shadow=True)\n",
        "env = RecordEpisode(env, \"./videos\", max_steps_per_video=100, save_trajectory=False)\n",
        "\n",
        "# step through the environment with random actions\n",
        "obs, _ = env.reset(seed=0)\n",
        "for i in tqdm(range(100)):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, terminated, truncated, info = env.step(torch.from_numpy(action))\n",
        "env.close()\n",
        "Video(\"./videos/0.mp4\", embed=True, width=640) # Watch our replay"
      ],
      "metadata": {
        "id": "UmTdlLpBp7BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"OpenCabinetDrawer-v1\", num_envs=4, control_mode=\"pd_joint_delta_pos\", render_mode=\"rgb_array\", enable_shadow=True)\n",
        "env = RecordEpisode(env, \"./videos\", max_steps_per_video=100, save_trajectory=False)\n",
        "\n",
        "obs, _ = env.reset(seed=0)\n",
        "for i in tqdm(range(100)):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, terminated, truncated, info = env.step(torch.from_numpy(action))\n",
        "env.close()\n",
        "Video(\"./videos/0.mp4\", embed=True, width=640) # Watch our replay"
      ],
      "metadata": {
        "id": "5eGb2_XSrChB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}